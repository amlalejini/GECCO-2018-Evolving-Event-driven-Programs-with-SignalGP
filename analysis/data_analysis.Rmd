---
title: "Data Analysis for Evolving Event-driven Programs with SignalGP (GECCO 2018)"
output: 
  html_document: 
    keep_md: yes
    toc: true
    toc_float: true
    toc_depth: 4
    collapsed: false
    theme: default
  pdf_document: default
---

## Overview
Here, we analyze the experimental results from our GECCO 2018 paper, "Evolving Event-driven Programs with SignalGP" (Lalejini and Ofria, 2018). 

### (just a little) Background
Our paper introduces SignalGP, a new genetic programming (GP) technique designed to provide evolution access to the [event-driven programming paradigm](https://en.wikipedia.org/wiki/Event-driven_programming). Additionally, we use SignalGP to demonstrate the value of evolving event-driven programs by evolving fully event-driven SignalGP programs and imperative variants of SignalGP programs to solve two problems: the changing environment problem and the distributed leader election problem. This document fully details the data analyses performed to analyze our experimental results for both of these problems. 

For the full context of these analyses, a detailed description of our experimental design, and musings on SignalGP, see our paper (Lalejini and Ofria, 2018). A pre-print can be found [here](https://arxiv.org/pdf/1804.05445.pdf).

## Source Code
The GitHub repository that contains the source code for this document and our experiments can be found here: [https://github.com/amlalejini/GECCO-2018-Evolving-Event-driven-Programs-with-SignalGP](https://github.com/amlalejini/GECCO-2018-Evolving-Event-driven-Programs-with-SignalGP). 

## Dependencies & General Setup
If you haven't noticed already, this is an R markdown file. We used `r version["version.string"]` for all statistical analyses (R Core Team, 2016). 

All Dunn's tests were performed using the FSA package (Ogle, 2017).
```{r, echo=TRUE}
library(FSA)
```

In addition to R, we used Python 3 for data manipulation and visualization. To get Python and R to place nice together, we use the [reticulate](https://rstudio.github.io/reticulate/index.html) R package.
```{r}
library(reticulate)
# We have to tell reticulate which python we want it to use.
use_python("/anaconda3/bin/python")
```
```{r setup}
knitr::knit_engines$set(python = reticulate::eng_python)
```

All visualizations use the seaborn Python package (Waskom et al., 2017), which wraps Python's matplotlib library, providing a "high-level interface for drawing attractive statistical graphics". 
```{python}
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
```

To handle our data on the Python side of things, we used the [pandas](https://pandas.pydata.org/) Python package, which provides "high-performance, easy-to-use data structures and data analysis tools for the Python programming language".
```{python}
import pandas as pd
```

---

## Problem: Changing Environment
### Description
The changing environment problem is a toy problem to test GP programs' capacity to respond appropriately to environmental signals. The changing environment problem is explicitly designed to be solved using the event-driven paradigm. Thus, under-performance by imperative SignalGP variants was expected. 

From our paper (Lalejini and Ofria, 2018):

> The changing environment problem requires agents to coordinate to coordinate their behavior with a randomly changing environment. The environment can be in one of _K_ possible states; to maximize fitness, agents must match their internal state to the current state of the environment. The environment is initialized to a random state and has a 12.5% chance of changing to a random state at every subsequent time step. Successful agents must adjust their internal state whenever an environmental change occurs. 

Agents adjust their internal state by executing on of _K_ state-altering instructions. Thus, to be successful, agents must monitor the environment state while adjusting their internal state as appropriate. 

To explore the value of giving evolution access to the event-driven programming paradigm, we compared the performance of programs with three different mechanisms for sensing the environment: 

1. an **event-driven treatment** where environmental changes produce signals that have environment-specific tags and can trigger SignalGP program functions
2. an **imperative control** where programs need to actively poll the environment to determine its state (using _K_ sensory instructions to test if the environment is in a particular state)
3. a **combined treatment** where agents are capable of using environmental signals or actively polling the environment

We evolved SignalGP agents to solve the changing environment problem at _K_ equal to 2, 4, 8, and 16 environmental states. The changing environment problem is designed to scale in difficulty as the number of environments increases.
We ran 100 replicate populations of each treatment at _K_ equal to 2, 4, 8, and 16 environmental states. In all replicates and across all treatments, we evolved populations of 1000 agents for 10,000 generations, starting from a simple ancestor program. 

### Statistical Methods
For every run, we extracted the program with the highest fitness after 10,000 generations of evolution. To account for environmental stochasticity, we tested each program 100 times, using a program's average performance as its fitness in our analyses. For each environmental size, we compared the performances of evolved programs across treatments. For our analyses, we set our significance level, $\alpha$, to:
```{r, echo=TRUE}
sig_level <- 0.05
```
To determine if any of the treatments were significant within a set (_p_ < `r sig_level`), we performed a [Kruskall-Wallis rank sum test](https://en.wikipedia.org/wiki/Kruskal%E2%80%93Wallis_one-way_analysis_of_variance). For a set in which the Kruskal-Wallis test was significant, we performed a post-hoc Dunn's test, applying a Bonferroni correction for multiple comparisons. 

### Results
Finally, enough with all of that mumbo-jumbo explanation stuff! Results! Pretty pictures! P values or whatever! 

But, before all that, we'll load in our data:
```{r}
chgenv_data <- read.csv("../data/chg_env/mt_final_fitness.csv")
```

A note about how treatments are named within the data: treatment names describe the parameters and their values used when running the experiment. Parameters and their values are adjacent in the name, and parameter-value combinations are separated by underscores. For example, ED1_AS1_ENV2_TSK0 indicates that event-driven (ED) signals were enabled (1), active sensors (AS) were enabled (1), and there were two environments states. In other words, ED1_AS1_ENV2_TSK0 indicates the two-state environment combined treatment. The trailing TSK0 can be ignored. 

#### Two-state Environment
Let's partition out the two-state environment data:
```{r}
chgenv_s2_data <- chgenv_data[grep("_ENV2_", chgenv_data$treatment),]
chgenv_s2_data <- chgenv_s2_data[chgenv_s2_data$analysis == "fdom",]
chgenv_s2_data$treatment <- relevel(chgenv_s2_data$treatment, ref="ED1_AS1_ENV2_TSK0")
```

**Accio, visualization!**

```{python, echo=FALSE}
# Some constants
labels =  ['Imperative', "Event-driven", 'Combined']
order_2=["ED0_AS1_ENV2_TSK0", "ED1_AS0_ENV2_TSK0", "ED1_AS1_ENV2_TSK0"]

min_fitness = 0.0
max_fitness = 256.0

x_tick_fs = 16
y_tick_fs = 16
y_label_fs = 18
x_label_fs = 18

fig = plt.figure(1)
gridspec.GridSpec(1,12)
fig.set_size_inches(10, 6)

with sns.axes_style("darkgrid"):
  ax1 = plt.subplot2grid((1,12), (0,0), colspan=12)
  p1 = sns.boxplot(x="treatment", y="fitness", data=r.chgenv_s2_data, ax=ax1, orient="v", order=order_2)
  sns.swarmplot(x="treatment", y="fitness", data=r.chgenv_s2_data, ax=ax1, color=".1", orient="v", order=order_2)
  
  ax1.set_xticklabels(labels)
  ax1.set_xlabel("Treatment")
  
  ax1.set_ylabel("Fitness")
  ax1.set_ylim(min_fitness, max_fitness + 10)
  
  for tick in ax1.get_yticklabels():
    tick.set_fontsize(y_tick_fs)
  
  for tick in ax1.get_xticklabels():
    tick.set_fontsize(x_tick_fs)
  
  ax1.yaxis.label.set_fontsize(y_label_fs)
  ax1.xaxis.label.set_fontsize(x_label_fs)
  
plt.show()

```

From the boxplot, the event-driven and combined treatments alone are able to produce optimally-performing programs. But, we'll be responsible and perform some actual statistical analyses.

First, we'll do a Kruskal-Wallis test to confirm that at least one of the treatments within the set is different from the others.
```{r, echo=TRUE}
chgenv_s2_kt <- kruskal.test(fitness ~ treatment, chgenv_s2_data)
chgenv_s2_kt
```

According to the Kruskal-Wallis test, at least one treatment is significantly different from the others. Next, we'll do a post-hoc Dunn's test, applying a Bonferroni correction for multiple comparisons.
```{r, echo=TRUE}
chgenv_s2_dt <- dunnTest(fitness ~ treatment, data=chgenv_s2_data, method="bonferroni")
chgenv_s2_dt_comps <- chgenv_s2_dt$res$Comparison
chgenv_s2_dt
```

```{python, echo=FALSE}
chgenv_name_mapping = {"ED1_AS0": "Event-driven", "ED0_AS1": "Imperative", "ED1_AS1": "Combined"}
def PrintDT(dt_results, comps, labels):
  pretty_comps = [comp for comp in comps]
  
  for label in labels:
    for ci in range(0, len(pretty_comps)):
      pretty_comps[ci] = " ".join([labels[label] if label in word else word for word in pretty_comps[ci].split(" ")])
  
  padj = dt_results["res"]["P.adj"]
  z = dt_results["res"]["Z"]
  
  sig = [i for i in range(0, len(comps)) if padj[i] < r.sig_level]
  notsig = [i for i in range(0, len(comps)) if padj[i] >= r.sig_level]
  
  print("===== Significant comparisons: =====")
  for i in sig:
    print("{}\n  adjusted p-value: {}\n  Z statistic: {}".format(pretty_comps[i], padj[i], z[i]))
  
  print("===== Not significant comparisons: =====")
  for i in notsig:
    print("{}\n adjusted p-value: {}\n Z statistic: {}".format(pretty_comps[i], padj[i], z[i]))
  
```

We'll use some Python code (most of which is under the hood of this document; check out the source code on Git to stare directly into the sun) to pretty-print our Dunn's test results. 
```{python, echo=FALSE}
PrintDT(r.chgenv_s2_dt, r.chgenv_s2_dt_comps, labels=chgenv_name_mapping)
```

What we saw in the boxplot is confirmed: the imperative treatment produced significantly lower performing than the combined or event-driven treatment. 

##### Teasing Apart the Combined Treatment
In the combined treatment, evolution had access to both the event-driven (signal-based) strategy and the imperative (sensor-polling) strategy. As shown above, performance in the event-driven and combined treatments did not significantly differ. However, this result along does not reveal what strategies were favored in the combined treatment. 

To tease this apart, we re-evaluated programs evolved under the combined treatment in two distinct conditions: one in which we deactivated polling sensors and one in which we prevented environment change signals from triggering functions in SignalGP functions.

First, we'll extract the relevant data. 
```{r, echo=TRUE}
chgenv_s2_comb_data <- chgenv_data[grep("ED1_AS1_ENV2_", chgenv_data$treatment),]
```

Visualize!
```{python, echo=FALSE}
# Some constants
labels =  ['Base', "No Sensors", "No Signals"]
xorder = ["fdom","no_sensors","no_signals"]

min_fitness = 0.0
max_fitness = 256.0

x_tick_fs = 16
y_tick_fs = 16
y_label_fs = 18
x_label_fs = 18

fig = plt.figure(1)
gridspec.GridSpec(1,12)
fig.set_size_inches(10, 6)

with sns.axes_style("darkgrid"):
  ax1 = plt.subplot2grid((1,12), (0,0), colspan=12)
  p1 = sns.boxplot(x="analysis", y="fitness", data=r.chgenv_s2_comb_data, ax=ax1, orient="v", order=xorder)
  sns.swarmplot(x="analysis", y="fitness", data=r.chgenv_s2_comb_data, ax=ax1, color=".1", orient="v", order=xorder)
  
  ax1.set_xticklabels(labels)
  ax1.set_xlabel("Analysis")
  
  ax1.set_ylabel("Fitness")
  ax1.set_ylim(min_fitness, max_fitness + 10)
  
  for tick in ax1.get_yticklabels():
    tick.set_fontsize(y_tick_fs)
  
  for tick in ax1.get_xticklabels():
    tick.set_fontsize(x_tick_fs)
  
  ax1.yaxis.label.set_fontsize(y_label_fs)
  ax1.xaxis.label.set_fontsize(x_label_fs)
  
plt.show()
```

When we take away signals, performance decreases; however, when we take away sensors, there's no effect. 

Stats to confirm!

First, we'll do a Kruskal-Wallis test to confirm that at least one of the treatments within the set is different from the others.
```{r, echo=TRUE}
chgenv_s2_comb_kt <- kruskal.test(fitness ~ analysis, chgenv_s2_comb_data)
chgenv_s2_comb_kt
```

According to the Kruskal-Wallis test, at least one treatment is significantly different from the others. Next, we'll do a post-hoc Dunn's test, applying a Bonferroni correction for multiple comparisons.
```{r, echo=TRUE}
chgenv_s2_comb_dt <- dunnTest(fitness ~ analysis, data=chgenv_s2_comb_data, method="bonferroni")
chgenv_s2_comb_dt_comps <- chgenv_s2_comb_dt$res$Comparison
chgenv_s2_comb_dt
```

Yup!

#### Four-state Environment
**Spoiler alert!** The four-, eight-, and sixteen- state environments are all pretty much the same story as the two-state environment. I'm going to cut out most of the commentary for the rest of these results. 

Let's partition out the four-state environment data:
```{r}
chgenv_s4_fdom_data <- chgenv_data[grep("_ENV4_", chgenv_data$treatment),]
chgenv_s4_fdom_data <- chgenv_s4_fdom_data[chgenv_s4_fdom_data$analysis == "fdom",]
chgenv_s4_fdom_data$treatment <- relevel(chgenv_s4_fdom_data$treatment, ref="ED1_AS1_ENV4_TSK0")
```

**Accio, visualization!**

```{python, echo=FALSE}
# Some constants
labels =  ['Imperative', "Event-driven", 'Combined']
orderx=["ED0_AS1_ENV4_TSK0", "ED1_AS0_ENV4_TSK0", "ED1_AS1_ENV4_TSK0"]

min_fitness = 0.0
max_fitness = 256.0

x_tick_fs = 16
y_tick_fs = 16
y_label_fs = 18
x_label_fs = 18

fig = plt.figure(1)
gridspec.GridSpec(1,12)
fig.set_size_inches(10, 6)

with sns.axes_style("darkgrid"):
  ax1 = plt.subplot2grid((1,12), (0,0), colspan=12)
  p1 = sns.boxplot(x="treatment", y="fitness", data=r.chgenv_s4_fdom_data, ax=ax1, orient="v", order=orderx)
  sns.swarmplot(x="treatment", y="fitness", data=r.chgenv_s4_fdom_data, ax=ax1, color=".1", orient="v", order=orderx)
  
  ax1.set_xticklabels(labels)
  ax1.set_xlabel("Treatment")
  
  ax1.set_ylabel("Fitness")
  ax1.set_ylim(min_fitness, max_fitness + 10)
  
  for tick in ax1.get_yticklabels():
    tick.set_fontsize(y_tick_fs)
  
  for tick in ax1.get_xticklabels():
    tick.set_fontsize(x_tick_fs)
  
  ax1.yaxis.label.set_fontsize(y_label_fs)
  ax1.xaxis.label.set_fontsize(x_label_fs)
  
plt.show()

```

From the boxplot, the event-driven and combined treatments alone are able to produce optimally-performing programs. But, we'll be responsible and perform some actual statistical analyses.

First, we'll do a Kruskal-Wallis test to confirm that at least one of the treatments within the set is different from the others.
```{r, echo=TRUE}
chgenv_s4_fdom_kt <- kruskal.test(fitness ~ treatment, chgenv_s4_fdom_data)
chgenv_s4_fdom_kt
```

According to the Kruskal-Wallis test, at least one treatment is significantly different from the others. Next, we'll do a post-hoc Dunn's test, applying a Bonferroni correction for multiple comparisons.
```{r, echo=TRUE}
chgenv_s4_fdom_dt <- dunnTest(fitness ~ treatment, data=chgenv_s4_fdom_data, method="bonferroni")
chgenv_s4_fdom_dt_comps <- chgenv_s4_fdom_dt$res$Comparison
chgenv_s4_fdom_dt
```


```{python, echo=FALSE}
PrintDT(r.chgenv_s4_fdom_dt, r.chgenv_s4_fdom_dt_comps, labels=chgenv_name_mapping)
```

##### Teasing Apart the Combined Treatment
In the combined treatment, evolution had access to both the event-driven (signal-based) strategy and the imperative (sensor-polling) strategy. As shown above, performance in the event-driven and combined treatments did not significantly differ. However, this result along does not reveal what strategies were favored in the combined treatment. 

To tease this apart, we re-evaluated programs evolved under the combined treatment in two distinct conditions: one in which we deactivated polling sensors and one in which we prevented environment change signals from triggering functions in SignalGP functions.

First, we'll extract the relevant data. 
```{r, echo=TRUE}
chgenv_s4_comb_data <- chgenv_data[grep("ED1_AS1_ENV4_", chgenv_data$treatment),]
```

Visualize!
```{python, echo=FALSE}
# Some constants
labels =  ['Base', "No Sensors", "No Signals"]
xorder = ["fdom","no_sensors","no_signals"]

min_fitness = 0.0
max_fitness = 256.0

x_tick_fs = 16
y_tick_fs = 16
y_label_fs = 18
x_label_fs = 18

fig = plt.figure(1)
gridspec.GridSpec(1,12)
fig.set_size_inches(10, 6)

with sns.axes_style("darkgrid"):
  ax1 = plt.subplot2grid((1,12), (0,0), colspan=12)
  p1 = sns.boxplot(x="analysis", y="fitness", data=r.chgenv_s4_comb_data, ax=ax1, orient="v", order=xorder)
  sns.swarmplot(x="analysis", y="fitness", data=r.chgenv_s4_comb_data, ax=ax1, color=".1", orient="v", order=xorder)
  
  ax1.set_xticklabels(labels)
  ax1.set_xlabel("Analysis")
  
  ax1.set_ylabel("Fitness")
  ax1.set_ylim(min_fitness, max_fitness + 10)
  
  for tick in ax1.get_yticklabels():
    tick.set_fontsize(y_tick_fs)
  
  for tick in ax1.get_xticklabels():
    tick.set_fontsize(x_tick_fs)
  
  ax1.yaxis.label.set_fontsize(y_label_fs)
  ax1.xaxis.label.set_fontsize(x_label_fs)
  
plt.show()
```

When we take away signals, performance decreases; however, when we take away sensors, there's no effect. 

Stats to confirm!

First, we'll do a Kruskal-Wallis test to confirm that at least one of the treatments within the set is different from the others.
```{r, echo=TRUE}
chgenv_s4_comb_kt <- kruskal.test(fitness ~ analysis, chgenv_s4_comb_data)
chgenv_s4_comb_kt
```

According to the Kruskal-Wallis test, at least one treatment is significantly different from the others. Next, we'll do a post-hoc Dunn's test, applying a Bonferroni correction for multiple comparisons.
```{r, echo=TRUE}
chgenv_s4_comb_dt <- dunnTest(fitness ~ analysis, data=chgenv_s4_comb_data, method="bonferroni")
chgenv_s4_comb_dt_comps <- chgenv_s4_comb_dt$res$Comparison
chgenv_s4_comb_dt
```

#### Eight-state Environment

Let's partition out the eight-state environment data:
```{r}
chgenv_s8_fdom_data <- chgenv_data[grep("_ENV8_", chgenv_data$treatment),]
chgenv_s8_fdom_data <- chgenv_s8_fdom_data[chgenv_s8_fdom_data$analysis == "fdom",]
chgenv_s8_fdom_data$treatment <- relevel(chgenv_s8_fdom_data$treatment, ref="ED1_AS1_ENV8_TSK0")
```

**Accio, visualization!**

```{python, echo=FALSE}
# Some constants
labels =  ['Imperative', "Event-driven", 'Combined']
orderx=["ED0_AS1_ENV8_TSK0", "ED1_AS0_ENV8_TSK0", "ED1_AS1_ENV8_TSK0"]

min_fitness = 0.0
max_fitness = 256.0

x_tick_fs = 16
y_tick_fs = 16
y_label_fs = 18
x_label_fs = 18

fig = plt.figure(1)
gridspec.GridSpec(1,12)
fig.set_size_inches(10, 6)

with sns.axes_style("darkgrid"):
  ax1 = plt.subplot2grid((1,12), (0,0), colspan=12)
  p1 = sns.boxplot(x="treatment", y="fitness", data=r.chgenv_s8_fdom_data, ax=ax1, orient="v", order=orderx)
  sns.swarmplot(x="treatment", y="fitness", data=r.chgenv_s8_fdom_data, ax=ax1, color=".1", orient="v", order=orderx)
  
  ax1.set_xticklabels(labels)
  ax1.set_xlabel("Treatment")
  
  ax1.set_ylabel("Fitness")
  ax1.set_ylim(min_fitness, max_fitness + 10)
  
  for tick in ax1.get_yticklabels():
    tick.set_fontsize(y_tick_fs)
  
  for tick in ax1.get_xticklabels():
    tick.set_fontsize(x_tick_fs)
  
  ax1.yaxis.label.set_fontsize(y_label_fs)
  ax1.xaxis.label.set_fontsize(x_label_fs)
  
plt.show()

```

From the boxplot, the event-driven and combined treatments alone are able to produce optimally-performing programs. But, we'll be responsible and perform some actual statistical analyses.

First, we'll do a Kruskal-Wallis test to confirm that at least one of the treatments within the set is different from the others.
```{r, echo=TRUE}
chgenv_s8_fdom_kt <- kruskal.test(fitness ~ treatment, chgenv_s8_fdom_data)
chgenv_s8_fdom_kt
```

According to the Kruskal-Wallis test, at least one treatment is significantly different from the others. Next, we'll do a post-hoc Dunn's test, applying a Bonferroni correction for multiple comparisons.
```{r, echo=TRUE}
chgenv_s8_fdom_dt <- dunnTest(fitness ~ treatment, data=chgenv_s8_fdom_data, method="bonferroni")
chgenv_s8_fdom_dt_comps <- chgenv_s8_fdom_dt$res$Comparison
chgenv_s8_fdom_dt
```


```{python, echo=FALSE}
PrintDT(r.chgenv_s8_fdom_dt, r.chgenv_s8_fdom_dt_comps, labels=chgenv_name_mapping)
```

##### Teasing Apart the Combined Treatment
In the combined treatment, evolution had access to both the event-driven (signal-based) strategy and the imperative (sensor-polling) strategy. As shown above, performance in the event-driven and combined treatments did not significantly differ. However, this result along does not reveal what strategies were favored in the combined treatment. 

To tease this apart, we re-evaluated programs evolved under the combined treatment in two distinct conditions: one in which we deactivated polling sensors and one in which we prevented environment change signals from triggering functions in SignalGP functions.

First, we'll extract the relevant data. 
```{r, echo=TRUE}
chgenv_s8_comb_data <- chgenv_data[grep("ED1_AS1_ENV8_", chgenv_data$treatment),]
```

Visualize!
```{python, echo=FALSE}
# Some constants
labels =  ['Base', "No Sensors", "No Signals"]
xorder = ["fdom","no_sensors","no_signals"]

min_fitness = 0.0
max_fitness = 256.0

x_tick_fs = 16
y_tick_fs = 16
y_label_fs = 18
x_label_fs = 18

fig = plt.figure(1)
gridspec.GridSpec(1,12)
fig.set_size_inches(10, 6)

with sns.axes_style("darkgrid"):
  ax1 = plt.subplot2grid((1,12), (0,0), colspan=12)
  p1 = sns.boxplot(x="analysis", y="fitness", data=r.chgenv_s8_comb_data, ax=ax1, orient="v", order=xorder)
  sns.swarmplot(x="analysis", y="fitness", data=r.chgenv_s8_comb_data, ax=ax1, color=".1", orient="v", order=xorder)
  
  ax1.set_xticklabels(labels)
  ax1.set_xlabel("Analysis")
  
  ax1.set_ylabel("Fitness")
  ax1.set_ylim(min_fitness, max_fitness + 10)
  
  for tick in ax1.get_yticklabels():
    tick.set_fontsize(y_tick_fs)
  
  for tick in ax1.get_xticklabels():
    tick.set_fontsize(x_tick_fs)
  
  ax1.yaxis.label.set_fontsize(y_label_fs)
  ax1.xaxis.label.set_fontsize(x_label_fs)
  
plt.show()
```

When we take away signals, performance crashes hard; however, when we take away sensors, there's no effect. 

Stats to confirm!

First, we'll do a Kruskal-Wallis test to confirm that at least one of the treatments within the set is different from the others.
```{r, echo=TRUE}
chgenv_s8_comb_kt <- kruskal.test(fitness ~ analysis, chgenv_s8_comb_data)
chgenv_s8_comb_kt
```

According to the Kruskal-Wallis test, at least one treatment is significantly different from the others. Next, we'll do a post-hoc Dunn's test, applying a Bonferroni correction for multiple comparisons.
```{r, echo=TRUE}
chgenv_s8_comb_dt <- dunnTest(fitness ~ analysis, data=chgenv_s8_comb_data, method="bonferroni")
chgenv_s8_comb_dt_comps <- chgenv_s8_comb_dt$res$Comparison
chgenv_s8_comb_dt
```


#### Sixteen-state environment

Let's partition out the sixteen-state environment data:
```{r}
chgenv_s16_fdom_data <- chgenv_data[grep("_ENV16_", chgenv_data$treatment),]
chgenv_s16_fdom_data <- chgenv_s16_fdom_data[chgenv_s16_fdom_data$analysis == "fdom",]
chgenv_s16_fdom_data$treatment <- relevel(chgenv_s16_fdom_data$treatment, ref="ED1_AS1_ENV16_TSK0")
```

**Accio, visualization!**

```{python, echo=FALSE}
# Some constants
labels =  ['Imperative', "Event-driven", 'Combined']
orderx=["ED0_AS1_ENV16_TSK0", "ED1_AS0_ENV16_TSK0", "ED1_AS1_ENV16_TSK0"]

min_fitness = 0.0
max_fitness = 256.0

x_tick_fs = 16
y_tick_fs = 16
y_label_fs = 18
x_label_fs = 18

fig = plt.figure(1)
gridspec.GridSpec(1,12)
fig.set_size_inches(10, 6)

with sns.axes_style("darkgrid"):
  ax1 = plt.subplot2grid((1,12), (0,0), colspan=12)
  p1 = sns.boxplot(x="treatment", y="fitness", data=r.chgenv_s16_fdom_data, ax=ax1, orient="v", order=orderx)
  sns.swarmplot(x="treatment", y="fitness", data=r.chgenv_s16_fdom_data, ax=ax1, color=".1", orient="v", order=orderx)
  
  ax1.set_xticklabels(labels)
  ax1.set_xlabel("Treatment")
  
  ax1.set_ylabel("Fitness")
  ax1.set_ylim(min_fitness, max_fitness + 10)
  
  for tick in ax1.get_yticklabels():
    tick.set_fontsize(y_tick_fs)
  
  for tick in ax1.get_xticklabels():
    tick.set_fontsize(x_tick_fs)
  
  ax1.yaxis.label.set_fontsize(y_label_fs)
  ax1.xaxis.label.set_fontsize(x_label_fs)
  
plt.show()

```

From the boxplot, the event-driven and combined treatments produce higher-performing programs than the imperative treatment. 

**NOTE:** Since running this experiment (and submitting the associated paper), I've done a bit more parameter exploration with SignalGP. The performance of the event-driven and combined treatments suffered from an astronomically high tag mutation rate. In subsequent work, I've lowered the tag mutation rate, and SignalGP can easily solve the 16-state environment in 10K generations. 

First, we'll do a Kruskal-Wallis test to confirm that at least one of the treatments within the set is different from the others.
```{r, echo=TRUE}
chgenv_s16_fdom_kt <- kruskal.test(fitness ~ treatment, chgenv_s16_fdom_data)
chgenv_s16_fdom_kt
```

According to the Kruskal-Wallis test, at least one treatment is significantly different from the others. Next, we'll do a post-hoc Dunn's test, applying a Bonferroni correction for multiple comparisons.
```{r, echo=TRUE}
chgenv_s16_fdom_dt <- dunnTest(fitness ~ treatment, data=chgenv_s16_fdom_data, method="bonferroni")
chgenv_s16_fdom_dt_comps <- chgenv_s16_fdom_dt$res$Comparison
chgenv_s16_fdom_dt
```


```{python, echo=FALSE}
PrintDT(r.chgenv_s16_fdom_dt, r.chgenv_s16_fdom_dt_comps, labels=chgenv_name_mapping)
```

##### Teasing Apart the Combined Treatment
In the combined treatment, evolution had access to both the event-driven (signal-based) strategy and the imperative (sensor-polling) strategy. As shown above, performance in the event-driven and combined treatments did not significantly differ. However, this result along does not reveal what strategies were favored in the combined treatment. 

To tease this apart, we re-evaluated programs evolved under the combined treatment in two distinct conditions: one in which we deactivated polling sensors and one in which we prevented environment change signals from triggering functions in SignalGP functions.

First, we'll extract the relevant data. 
```{r, echo=TRUE}
chgenv_s16_comb_data <- chgenv_data[grep("ED1_AS1_ENV16_", chgenv_data$treatment),]
```

Visualize!
```{python, echo=FALSE}
# Some constants
labels =  ['Base', "No Sensors", "No Signals"]
xorder = ["fdom","no_sensors","no_signals"]

min_fitness = 0.0
max_fitness = 256.0

x_tick_fs = 16
y_tick_fs = 16
y_label_fs = 18
x_label_fs = 18

fig = plt.figure(1)
gridspec.GridSpec(1,12)
fig.set_size_inches(10, 6)

with sns.axes_style("darkgrid"):
  ax1 = plt.subplot2grid((1,12), (0,0), colspan=12)
  p1 = sns.boxplot(x="analysis", y="fitness", data=r.chgenv_s16_comb_data, ax=ax1, orient="v", order=xorder)
  sns.swarmplot(x="analysis", y="fitness", data=r.chgenv_s16_comb_data, ax=ax1, color=".1", orient="v", order=xorder)
  
  ax1.set_xticklabels(labels)
  ax1.set_xlabel("Analysis")
  
  ax1.set_ylabel("Fitness")
  ax1.set_ylim(min_fitness, max_fitness + 10)
  
  for tick in ax1.get_yticklabels():
    tick.set_fontsize(y_tick_fs)
  
  for tick in ax1.get_xticklabels():
    tick.set_fontsize(x_tick_fs)
  
  ax1.yaxis.label.set_fontsize(y_label_fs)
  ax1.xaxis.label.set_fontsize(x_label_fs)
  
plt.show()
```

When we take away signals, performance crashes hard; however, when we take away sensors, there's no effect. 

Stats to confirm!

First, we'll do a Kruskal-Wallis test to confirm that at least one of the treatments within the set is different from the others.
```{r, echo=TRUE}
chgenv_s16_comb_kt <- kruskal.test(fitness ~ analysis, chgenv_s16_comb_data)
chgenv_s16_comb_kt
```

According to the Kruskal-Wallis test, at least one treatment is significantly different from the others. Next, we'll do a post-hoc Dunn's test, applying a Bonferroni correction for multiple comparisons.
```{r, echo=TRUE}
chgenv_s16_comb_dt <- dunnTest(fitness ~ analysis, data=chgenv_s16_comb_data, method="bonferroni")
chgenv_s16_comb_dt_comps <- chgenv_s16_comb_dt$res$Comparison
chgenv_s16_comb_dt
```

---


## Problem: Distributed Leader Election

### Description
From our paper (Lalejini and Ofria, 2018):
> In the distributed leader election problem, a network of agents must unanimously designate a single agent as leader. Agents are each given a unique identifer (UID). Initially, agents are only aware of their own UID and must communicate to resolve the UIDs of other agents. During an election, each agent may vote, and an election is successful if all votes converge to a single, consensus UID. 

We evolved populations of homogeneous distributed systems of SignalGP agents where networks were configured as 5x5 toroidal grids, and agents could only interact with their four neighbors. Distrubed systems maximize their fitness by achieving consensus as quickly as possible and maintaining consensus for the duration of the evaluation (see paper for exact fitness function used). We reward partial solutions by taking into account valid votes and partial consensus at the end of an evaluation. 

We evolved distributed systems in three treatments:

1. one with event-driven messaging where messages were signals (events) that could trigger a SignalGP program function when received 
2. imperative messaging with fork on message
3. imperative messaging without fork on message

Treatments 2 and 3 were imperative variants; see paper for exact details on the differences between the two. 

We evolved 100 replicate populations (size of 400 distributed systems) of each treatment for 50,000 generations, starting from a simple ancestor program. 

### Statistical Methods
For every replicate across all treatments we extracted the program that produced the most fit distributed system after 50,000 generations of evolution. We compared the performances of evolved programs across treatments. For our analyses, we set our significance level, α, equal to `r sig_level`. To determine if any of the treatments were significant within a set (_p_ < `r sig_level`), we performed a Kruskal-Wallis rank sum test. For a set in which the Kruskal-Wallis test was significant, we performed a post-hoc Dunn's test, applying a Bonferroni correction for multiple comparisons. 

### Results

Let's load the election results in using R. 
```{r, echo=TRUE}
election_data <- read.csv("../data/election/final_fitness.csv")
election_data_overtime <- read.csv("../data/election/fitness_over_time.csv")
```

Visualize! 

```{python, echo=FALSE}
# Some constants
labels =  ['Event-driven', "Imperative\n(fork-on-retr.)", 'Imperative\n(copy-on-retr.)']
orderx=["EventDriven_MsgForking", "Imperative_MsgForking", "Imperative_MsgNonForking"]

min_fitness = 0.0
max_fitness = 7000

x_tick_fs = 16
y_tick_fs = 16
y_label_fs = 18
x_label_fs = 18

fig = plt.figure(1)
gridspec.GridSpec(1,12)
fig.set_size_inches(10, 6)

with sns.axes_style("darkgrid"):
  ax1 = plt.subplot2grid((1,12), (0,0), colspan=12)
  p1 = sns.boxplot(x="treatment", y="max_fitness", data=r.election_data, ax=ax1, orient="v", order=orderx)
  sns.swarmplot(x="treatment", y="max_fitness", data=r.election_data, ax=ax1, color=".1", orient="v", order=orderx)
  
  ax1.set_xticklabels(labels)
  ax1.set_xlabel("Treatment")
  
  ax1.set_ylabel("Fitness")
  ax1.set_ylim(min_fitness, max_fitness + 10)
  
  for tick in ax1.get_yticklabels():
    tick.set_fontsize(y_tick_fs)
  
  for tick in ax1.get_xticklabels():
    tick.set_fontsize(x_tick_fs)
  
  ax1.yaxis.label.set_fontsize(y_label_fs)
  ax1.xaxis.label.set_fontsize(x_label_fs)
  
plt.show()
```

Let's also look at fitness over time. (colors on timeseries are paired with colors on boxplot)

```{python, echo=FALSE}
# Some constants
labels =  ['Event-driven', "Imperative\n(fork-on-retr.)", 'Imperative\n(copy-on-retr.)']
orderx=["EventDriven_MsgForking", "Imperative_MsgForking", "Imperative_MsgNonForking"]

min_fitness = 0.0
max_fitness = 7000

x_tick_fs = 16
y_tick_fs = 16
y_label_fs = 18
x_label_fs = 18

fig = plt.figure(1)
gridspec.GridSpec(1,12)
fig.set_size_inches(10, 6)

with sns.axes_style("darkgrid"):
  ax1 = plt.subplot2grid((1,12), (0,0), colspan=12)
  ploty = sns.tsplot(data=r.election_data_overtime, time="update", unit="run_id", err_style="ci_band",
           condition="treatment", value="max_fitness", ax = ax1, legend = False, ci=95)
  
  ax1.set_xticklabels([i for i in range(0, 50001, 10000)], rotation = 45)
  ax1.set_xlabel("Treatment")
  
  ax1.set_ylabel("Fitness")
  ax1.set_ylim(min_fitness, max_fitness + 10)
  
  for tick in ax1.get_yticklabels():
    tick.set_fontsize(y_tick_fs)
  
  for tick in ax1.get_xticklabels():
    tick.set_fontsize(x_tick_fs)
  
  ax1.yaxis.label.set_fontsize(y_label_fs)
  ax1.xaxis.label.set_fontsize(x_label_fs)
  
plt.show()
```

From the visualizations, it looks like the event-driven treatment outperforms (just a little) the imperative treatments. 

First, we'll do a Kruskal-Wallis test to confirm that at least one of the treatments within the set is different from the others.
```{r, echo=TRUE}
elec_kw <- kruskal.test(max_fitness ~ treatment, data=election_data)
elec_kw
```

According to the Kruskal-Wallis test, at least one treatment is significantly different from the others. Next, we'll do a post-hoc Dunn's test, applying a Bonferroni correction for multiple comparisons.
```{r, echo=TRUE}
elec_dt <- dunnTest(max_fitness~treatment, data=election_data, method="bonferroni")
elec_dt
```

According to our Dunn's test, the event-driven treatment produced programs that significantly outperformed those evolved in both imperative treatments. Note, all treatments produced programs able to solve the distrubed leader election problem (no surprise since this problem is well-studied and previous work has used imperative LGP to evolve solutions). The difference in performance has to do with the efficiency at which event-driven programs are able to communicate with one another, not needing to check for received messages. 

---

## References
Lalejini, A., & Ofria, C. (2018). Evolving Event-driven Programs with SignalGP. In Proceedings of the Genetic and Evolutionary Computation Conference. ACM. https://doi.org/10.1145/3205455.3205523

Ogle, D.H. 2017. FSA: Fisheries Stock Analysis. R package version 0.8.17.

R Core Team (2016). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL https://www.R-project.org/.

Michael Waskom, Olga Botvinnik, Drew O'Kane, Paul Hobson, Saulius Lukauskas, David C Gemperline, … Adel Qalieh. (2017, September 3). mwaskom/seaborn: v0.8.1 (September 2017) (Version v0.8.1). Zenodo. http://doi.org/10.5281/zenodo.883859